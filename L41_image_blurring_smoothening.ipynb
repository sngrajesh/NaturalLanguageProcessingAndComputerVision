{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 20px;\n",
    "    font-weight: bold;\n",
    "    text-align: center;\">\n",
    "    Image Blurring and Smoothening\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 17px;\n",
    "    font-weight: bold;\n",
    "    text-align: center;\">\n",
    "    Kernel\n",
    "<br/>\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In computer vision, a **kernel**, also known as a convolution matrix or mask, is a smaller matrix used to manipulate images in various ways.\n",
    "\n",
    "- Think of it as a tiny **window** that `slides` across the image, performing calculations at each pixel based on the surrounding pixels and the kernel itself.\n",
    "\n",
    "- The calculations can achieve various effects, making kernels incredibly versatile tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('content/images/sachin.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Averaging Kernel}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816,\n",
       "        0.02040816, 0.02040816],\n",
       "       [0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816,\n",
       "        0.02040816, 0.02040816],\n",
       "       [0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816,\n",
       "        0.02040816, 0.02040816],\n",
       "       [0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816,\n",
       "        0.02040816, 0.02040816],\n",
       "       [0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816,\n",
       "        0.02040816, 0.02040816],\n",
       "       [0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816,\n",
       "        0.02040816, 0.02040816],\n",
       "       [0.02040816, 0.02040816, 0.02040816, 0.02040816, 0.02040816,\n",
       "        0.02040816, 0.02040816]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 7\n",
    "kernel = np.ones((size, size))*(1/size**2)\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "filter2D(src, ddepth, kernel[, dst[, anchor[, delta[, borderType]]]]) -> dst\n",
      ".   @brief Convolves an image with the kernel.\n",
      ".   \n",
      ".   The function applies an arbitrary linear filter to an image. In-place operation is supported. When\n",
      ".   the aperture is partially outside the image, the function interpolates outlier pixel values\n",
      ".   according to the specified border mode.\n",
      ".   \n",
      ".   The function does actually compute correlation, not the convolution:\n",
      ".   \n",
      ".   \\f[\\texttt{dst} (x,y) =  \\sum _{ \\substack{0\\leq x' < \\texttt{kernel.cols}\\\\{0\\leq y' < \\texttt{kernel.rows}}}}  \\texttt{kernel} (x',y')* \\texttt{src} (x+x'- \\texttt{anchor.x} ,y+y'- \\texttt{anchor.y} )\\f]\n",
      ".   \n",
      ".   That is, the kernel is not mirrored around the anchor point. If you need a real convolution, flip\n",
      ".   the kernel using #flip and set the new anchor to `(kernel.cols - anchor.x - 1, kernel.rows -\n",
      ".   anchor.y - 1)`.\n",
      ".   \n",
      ".   The function uses the DFT-based algorithm in case of sufficiently large kernels (~`11 x 11` or\n",
      ".   larger) and the direct algorithm for small kernels.\n",
      ".   \n",
      ".   @param src input image.\n",
      ".   @param dst output image of the same size and the same number of channels as src.\n",
      ".   @param ddepth desired depth of the destination image, see @ref filter_depths \"combinations\"\n",
      ".   @param kernel convolution kernel (or rather a correlation kernel), a single-channel floating point\n",
      ".   matrix; if you want to apply different kernels to different channels, split the image into\n",
      ".   separate color planes using split and process them individually.\n",
      ".   @param anchor anchor of the kernel that indicates the relative position of a filtered point within\n",
      ".   the kernel; the anchor should lie within the kernel; default value (-1,-1) means that the anchor\n",
      ".   is at the kernel center.\n",
      ".   @param delta optional value added to the filtered pixels before storing them in dst.\n",
      ".   @param borderType pixel extrapolation method, see #BorderTypes. #BORDER_WRAP is not supported.\n",
      ".   @sa  sepFilter2D, dft, matchTemplate\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "cv2.filter2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\n",
      "libGL error: MESA-LOADER: failed to open radeonsi: /usr/lib/dri/radeonsi_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: radeonsi\n",
      "libGL error: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: swrast\n"
     ]
    }
   ],
   "source": [
    "average_image = cv2.filter2D(img,-1,kernel)\n",
    "\n",
    "cv2.imshow('average_image',average_image)\n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
