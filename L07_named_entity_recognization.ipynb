{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 20px;\n",
    "    font-weight: bold;\n",
    "    text-align: center;\">\n",
    " Named Entity Recognition\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Named Entity Recognition (NER) - sometimes referred to as entity chunking, extraction, or identification is the task of identifying and categorizing key information(entities) in text.\n",
    "\n",
    "* An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category.\n",
    "\n",
    "* For example, an NER machine learning(ML) model might detect the word \"MITU Skillogies\" in a text and classify it as a \"Company\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 17px;\n",
    "    font-weight: bold;\n",
    "    text-align: center;\">\n",
    "    Using nltk <br>\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('maxent_ne_chunker_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Sachin/NNP)\n",
      "  (PERSON Tenduakal/NNP)\n",
      "  was/VBD\n",
      "  born/VBN\n",
      "  in/IN\n",
      "  (GPE Mumbai/NNP)\n",
      "  ,/,\n",
      "  (GPE India/NNP)\n",
      "  on/IN\n",
      "  April/NNP\n",
      "  24/CD\n",
      "  ,/,\n",
      "  1974/CD\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "text = 'Sachin Tenduakal was born in Mumbai, India on April 24, 1974.'\n",
    "\n",
    "\n",
    "tokens =word_tokenize(text)\n",
    "\n",
    "tagged_tokens = pos_tag(tokens)\n",
    "\n",
    "ner_tree = ne_chunk(tagged_tokens)\n",
    "print(ner_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Sachin', 'NNP'), 'PERSON'),\n",
       " (('Tenduakal', 'NNP'), 'PERSON'),\n",
       " (('was', 'VBD'), 'S'),\n",
       " (('born', 'VBN'), 'S'),\n",
       " (('in', 'IN'), 'S'),\n",
       " (('Mumbai', 'NNP'), 'GPE'),\n",
       " ((',', ','), 'S'),\n",
       " (('India', 'NNP'), 'GPE'),\n",
       " (('on', 'IN'), 'S'),\n",
       " (('April', 'NNP'), 'S'),\n",
       " (('24', 'CD'), 'S'),\n",
       " ((',', ','), 'S'),\n",
       " (('1974', 'CD'), 'S'),\n",
       " (('.', '.'), 'S')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tree.draw()\n",
    "ner_tree.pos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sachin', 'Tenduakal', 'Mumbai', 'India', 'April']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = [i[0][0] for i in ner_tree.pos() if i[0][1].startswith('NN')]\n",
    "nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 17px;\n",
    "    font-weight: bold;\n",
    "    text-align: center;\">\n",
    "    Using Spacy <br>\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: pathy>=0.10.0 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (1.10.19)\n",
      "Requirement already satisfied: jinja2 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (75.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from spacy) (3.4.1)\n",
      "Requirement already satisfied: language-data>=1.2 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from pathy>=0.10.0->spacy) (0.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in e:\\naturallanguageprocessingandcomputervision\\.nlpcv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install spacy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nlpcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
