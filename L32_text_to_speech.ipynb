{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 20px;\n",
    "    font-weight: bold;\n",
    "    text-align: center;\">\n",
    "    Text to Speech\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyttsx3\n",
      "  Downloading pyttsx3-2.98-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting gtts\n",
      "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting playsound\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting comtypes (from pyttsx3)\n",
      "  Downloading comtypes-1.4.8-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pypiwin32 (from pyttsx3)\n",
      "  Downloading pypiwin32-223-py3-none-any.whl.metadata (236 bytes)\n",
      "Requirement already satisfied: pywin32 in e:\\naturallanguageprocessingandcomputervision\\.env\\lib\\site-packages (from pyttsx3) (308)\n",
      "Requirement already satisfied: requests<3,>=2.27 in e:\\naturallanguageprocessingandcomputervision\\.env\\lib\\site-packages (from gtts) (2.32.3)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in e:\\naturallanguageprocessingandcomputervision\\.env\\lib\\site-packages (from gtts) (8.1.7)\n",
      "Requirement already satisfied: colorama in e:\\naturallanguageprocessingandcomputervision\\.env\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\naturallanguageprocessingandcomputervision\\.env\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\naturallanguageprocessingandcomputervision\\.env\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\naturallanguageprocessingandcomputervision\\.env\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\naturallanguageprocessingandcomputervision\\.env\\lib\\site-packages (from requests<3,>=2.27->gtts) (2024.8.30)\n",
      "Downloading pyttsx3-2.98-py3-none-any.whl (34 kB)\n",
      "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
      "Downloading comtypes-1.4.8-py3-none-any.whl (229 kB)\n",
      "Downloading pypiwin32-223-py3-none-any.whl (1.7 kB)\n",
      "Building wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py): started\n",
      "  Building wheel for playsound (setup.py): finished with status 'done'\n",
      "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7044 sha256=599bc12a3303237a8634456ab80ea2ba66721a95a04b2f3c0808b878253ce764\n",
      "  Stored in directory: c:\\users\\dai.studentsdc\\appdata\\local\\pip\\cache\\wheels\\cf\\42\\ff\\7c587bae55eec67b909ca316b250d9b4daedbf272a3cbeb907\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound, pypiwin32, comtypes, pyttsx3, gtts\n",
      "Successfully installed comtypes-1.4.8 gtts-2.5.4 playsound-1.3.0 pypiwin32-223 pyttsx3-2.98\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3 gtts playsound -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 17px;\n",
    "    font-weight: bold;\n",
    "    text-align: center;\">\n",
    "    Using gTTS\n",
    "<br/>\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS           # Class\n",
    "from playsound import playsound # Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"\n",
    "\"Attention Is All You Need\"[1] is a 2017 landmark[2][3] research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al.[4] It is considered a foundational[5] paper in modern artificial intelligence, as the transformer approach has become the main architecture of large language models like those based on GPT.[6][7] At the time, the focus of the research was on improving Seq2seq techniques for machine translation, but the authors go further in the paper, foreseeing the technique's potential for other tasks like question answering and what is now known as multimodal Generative AI.[1]\n",
    "\n",
    "The paper's title is a reference to the song \"All You Need Is Love\" by the Beatles.[8] The name \"Transformer\" was picked because Jakob Uszkoreit, one of the paper's authors, liked the sound of that word.[9]\n",
    "\n",
    "An early design document was titled \"Transformers: Iterative Self-Attention and Processing for Various Tasks\", and included an illustration of six characters from the Transformers animated show. The team was named Team Transformer.[8]\n",
    "\n",
    "Some early examples that the team tried their Transformer architecture on included English-to-German translation, generating Wikipedia articles on \"The Transformer\", and parsing. These convinced the team that the Transformer is a general purpose language model, and not just good for translation.[9]\n",
    "\"\"\"\n",
    "\n",
    "gtts = gTTS(text=text, lang='en')\n",
    "gtts.save('text_to_speech_transformers.mp3')\n",
    "gtts.speed = 0.5\n",
    "\n",
    "playsound('text_to_speech_transformers.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''हमारे सौर मण्डल के सातवे ग्रह अरुण (युरेनस) के २८ ज्ञात प्राकृतिक उपग्रह हैं।[1] इनमें से पांच सब से बड़े चन्द्रमा अपने ही गुरुत्वाकर्षण के खिचाव से गोल हो चुके हैं जबकि बाक़ियों के अकार बेढंगे हैं, जैसा की प्राकृतिक उपग्रहों में आम देखा जाता है। इन सब चंद्रमाओं के नाम अंग्रेज़ी नाटककार विलियम शेक्सपीयर और लेखक अलेक्ज़ंडर पोप की कहानियों के पात्रों पर रखे गए हैं। सब से पहले ब्रिटिश वैज्ञानिक विलियम हरशॅल ने १७८७ में अरुण के सब से बड़े दो चंद्रमाओं - टाइटेनिआ और ओबेरॉन - की पाए जाने की घोषणा की थी। बाक़ी तीन गोलाकार चंद्रमाओं में से ऍरिअल और अम्ब्रिअल १८५१ में विलियम लैसॅल द्वारा और मिरैन्डा १९४८ में जॅरार्ड काइपर द्वारा खोजे गए थे। बाक़ी चन्द्रमा या तो वॉयेजर द्वितीय यान के अरुण के पास से गुज़रने पर या पृथ्वी पर स्थित ताक़तवर दूरबीनों से १९८५ के बाद पाए गए।'''\n",
    "\n",
    "\n",
    "gtts = gTTS(text=text, lang='hi')\n",
    "gtts.save('text_to_speech_hindi.mp3')\n",
    "\n",
    "playsound('text_to_speech_hindi.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could Not Find e:\\NaturalLanguageProcessingAndComputerVision\\text_to_speech_transformers.mp3\n"
     ]
    }
   ],
   "source": [
    "!del text_to_speech_transformers.mp3\n",
    "!del text_to_speech_hindi.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 17px;\n",
    "    font-weight: bold;\n",
    "    text-align: center;\">\n",
    "    Using pyttsx3\n",
    "<br/>\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "# Initialize the engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "\n",
    "# Set the voice\n",
    "engine.setProperty('rate', 150)\n",
    "engine.setProperty('volume', 1)\n",
    "\n",
    "text=\"\"\"\n",
    "\"Attention Is All You Need\"[1] is a 2017 landmark[2][3] research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al.[4] It is considered a foundational[5] paper in modern artificial intelligence, as the transformer approach has become the main architecture of large language models like those based on GPT.[6][7] At the time, the focus of the research was on improving Seq2seq techniques for machine translation, but the authors go further in the paper, foreseeing the technique's potential for other tasks like question answering and what is now known as multimodal Generative AI.[1]\n",
    "\n",
    "The paper's title is a reference to the song \"All You Need Is Love\" by the Beatles.[8] The name \"Transformer\" was picked because Jakob Uszkoreit, one of the paper's authors, liked the sound of that word.[9]\n",
    "\n",
    "An early design document was titled \"Transformers: Iterative Self-Attention and Processing for Various Tasks\", and included an illustration of six characters from the Transformers animated show. The team was named Team Transformer.[8]\n",
    "\n",
    "Some early examples that the team tried their Transformer architecture on included English-to-German translation, generating Wikipedia articles on \"The Transformer\", and parsing. These convinced the team that the Transformer is a general purpose language model, and not just good for translation.[9]\n",
    "\"\"\"\n",
    "\n",
    "# Speak the text\n",
    "engine.say(text)\n",
    "\n",
    "# Wait for the audio to finish playing\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[0].id)\n",
    "engine.say('Hello, My name is AI.') \n",
    "engine.runAndWait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
