{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Anatomy of Language}$$\n",
    "- Language \n",
    "    - Language is a structured system of communication. The structure of a language is its grammar and the free components are its vocabulary.\n",
    "        - Early Languages\n",
    "        - Modern Linguistics\n",
    "\n",
    "- Language as a phenomenon\n",
    "    - Language is considered as a social phenomenon because all human beings communicate with their respective speech communities using the language they speak.\n",
    "        - Spoken Language\n",
    "        - Written Language\n",
    "- Semantics\n",
    "    - Language exists to be meaningful; the study of meaning, both in general theoretical terms and in reference to a specific language, is known as semantics.\n",
    "    - Semantics embraces the meaningful functions of phonological features, such as intonation, and of grammatical structures and the meanings of individual words.\n",
    "\n",
    "- Language Variants\n",
    "    - Language refers to both the universal human ability to communicate and its specific forms, like English, French, or Swahili.\n",
    "\n",
    "- Physiological and physical basis\n",
    "    - Language originated as a spoken system, evolving naturally with human communication, while writing emerged only 4,000‚Äì5,000 years ago as a way to represent speech. For most of human history, language was passed down orally.\n",
    "\n",
    "- Speech Production\n",
    "    - Speaking arises from exhaling air during respiration, modified by vocal tract movements to produce various sounds.\n",
    "\n",
    "- Language Acquisition\n",
    "    - All humans are physiologically alike in speech production. Language is learned from upbringing, not inherited; adopted children acquire their adoptive parents' language.\n",
    "\n",
    "\n",
    "- Meaning and Style in Language\n",
    "    - Language exists to convey meaning, shaped by the diverse needs of human communication, making the study of meaning highly complex.\n",
    "\n",
    "- Structural, or grammatical, meaning\n",
    "    - Sentence meaning combines word meanings and grammatical structure, as seen in sentences like The dog chased the cat and The boy chased the cat.\n",
    "\n",
    "- Lexical meaning\n",
    "    - Word meaning, or lexical meaning, refers to the individual definitions of words, as outlined in dictionaries. Answering \"What does this word mean?\" is often harder than it seems.\n",
    "\n",
    "- Language and culture\n",
    "    - Language is deeply tied to community life and culture, shaping and reflecting the details of daily living universally across all languages.\n",
    "\n",
    "- Transmission of Language and culture\n",
    "    - Language is primarily learned through cultural exposure, with limited direct teaching, as children construct grammar from the speech they hear. Language is an integral part of culture, influencing and reflecting societal membership.\n",
    "\n",
    "- Symbolic Systems\n",
    "    - Symbolic systems represent the world using meaningful symbols, including human and computer languages.\n",
    "- Types of Languages \n",
    "    - Artificial Language \n",
    "        - Artificial languages arise from simulations, interactions, or experiments, evolving naturally rather than being consciously designed. They are used in cultural evolution studies and psycholinguistic research.\n",
    "    - Constructed Language\n",
    "        - Constructed languages, or conlangs, are intentionally designed for purposes like communication, fiction, experimentation, or art. Examples include international auxiliary languages and fictional languages.\n",
    "    - Logical Language\n",
    "        - Logical languages, such as Loglan and Lojban, use formal logic to eliminate ambiguity, aiming for precision in expression.\n",
    "    - Programming Language\n",
    "        - Programming languages, text-based or graphical, enable writing computer programs. They are defined by syntax and semantics, with some based on specifications (e.g., C) and others by dominant implementations (e.g., Perl).\n",
    "    - Natural Language\n",
    "        - Natural languages evolve naturally through human use and differ from artificial or constructed languages. They are systematic, conventional, redundant, and subject to change over time.\n",
    "        - Natural Imprecision\n",
    "            - Natural language reflects human cognition but includes vague terms like \"tall\" or \"hot,\" challenging precise translation into computational reasoning.\n",
    "- Linguistics\n",
    "    - Linguistics\n",
    "        - inguistics, the science of language, studies human communication, language families, and specific languages, involving subfields like phonetics, syntax, semantics, and sociolinguistics.\n",
    "    - Applied Linguistics\n",
    "        - Applied linguistics applies linguistic research to areas like education, translation, lexicography, language policy, and natural language processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Language Analysis and Computational Linguistics}$$\n",
    " \n",
    "- Language Analysis\n",
    "    - **Purpose**: To understand how meaning is conveyed using language techniques (e.g., tone, word choice).\n",
    "        - Identify techniques and their effects.\n",
    "\n",
    "- Techniques\n",
    "    - **Persuasive Techniques**: Analyze how these influence audience perception and response.\n",
    "\n",
    "- Levels of Analysis\n",
    "    - **Phonology**: Sound system of a language.\n",
    "    - **Grammar (Morphology/Syntax)**: Structure of words and sentences.\n",
    "    - **Discourse and Pragmatics**: Contextual and functional use of language.\n",
    "\n",
    "- Genre and Audience\n",
    "    - **Genre**: Groups texts by style and theme (e.g., fantasy, poetry).\n",
    "    - **Audience**: Tailors content to engage target readers effectively.\n",
    "\n",
    "- Foregrounding\n",
    "    - **Attention-Getting Techniques**: Uses repetition (parallelism) or breaks patterns (deviation).\n",
    "\n",
    "- Literariness\n",
    "    - **Value in Texts**: Aesthetic and moral qualities elevate texts to literary works.\n",
    "\n",
    "- Paradigm and Syntagm\n",
    "    - **Paradigm**: Substitution relationships (e.g., noun for noun).\n",
    "    - **Syntagm**: Positional relationships in sentence structure.\n",
    "\n",
    "- Form and Function\n",
    "    - **Form**: Identifies parts of speech and structures.\n",
    "    - **Function**: Explains roles (nominal, adjectival, adverbial) in context.\n",
    "\n",
    "- Linguistic Analysis\n",
    "    - **Focus Areas**:\n",
    "        - **Phonetics**: Studies sound production and perception.\n",
    "        - **Phonology**: Explores sound systems.\n",
    "        - **Morphology**: Investigates word structures.\n",
    "        - **Syntax**: Examines sentence formation rules.\n",
    "        - **Semantics**: Analyzes meaning.\n",
    "        - **Pragmatics**: Studies social use of language.\n",
    "\n",
    "- Lexicology\n",
    "    - **Word Analysis**: Examines formation, usage, and relationships between words.\n",
    "\n",
    "- Artificial Intelligence\n",
    "    - **Definition**: Simulates human intelligence to mimic cognitive tasks.\n",
    "        - **Strong AI**: Abstract reasoning and human-level thinking (future goal).\n",
    "        - **Weak AI**: Pattern-based automation (e.g., driving, translation).\n",
    "\n",
    "- AI Techniques\n",
    "    - **Logic and Rules-Based**: Top-down rules for reasoning.\n",
    "    - **Machine Learning**: Pattern detection for self-learning systems.\n",
    " \n",
    "- Branches of Artificial Intelligence\n",
    "    - Artificial Intelligence (AI) encompasses several key techniques and applications to solve real-world problems, including:  \n",
    "        - Machine Learning  \n",
    "        - Deep Learning  \n",
    "        - Natural Language Processing  \n",
    "        - Robotics  \n",
    "        - Expert Systems  \n",
    "        - Fuzzy Logic  \n",
    "\n",
    "\n",
    "- Machine Learning (ML)\n",
    "    - Machine learning, a subset of AI, enables systems to learn and improve from experience without explicit programming. ML systems analyze data, identify patterns, and make decisions with minimal human intervention. Its core goal is to allow computers to learn autonomously and refine their actions accordingly.\n",
    "    - ML focuses on developing algorithms that transform data into intelligent action. These algorithms find applications in various domains, such as predictive modeling and decision-making.\n",
    "\n",
    "\n",
    "- Deep Learning (DL)\n",
    "    - Deep learning is a specialized subset of ML that uses neural networks with multiple layers. These networks mimic human brain function to process large datasets. Additional layers in DL models enhance prediction accuracy by optimizing hidden patterns.\n",
    "\n",
    "\n",
    "- Robotics\n",
    "    - Robotics integrates engineering and AI to design, manufacture, and operate robots. These intelligent machines can assist humans in tasks ranging from industrial automation to healthcare services. Forms of robotics include humanoid robots and software-based robotic process automation (RPA).\n",
    "\n",
    "\n",
    "- Expert Systems\n",
    "    - Expert systems simulate human expertise using AI technologies. They combine a knowledge base of facts and rules with inference engines to solve domain-specific problems. While they complement human experts, they are not designed to replace them.\n",
    "\n",
    "\n",
    "- Fuzzy Logic\n",
    "    - Fuzzy logic introduces degrees of truth to computing, as opposed to binary true/false logic. It allows systems to handle uncertainty and approximate reasoning effectively, particularly in control systems and decision-making applications.\n",
    "\n",
    "\n",
    "- Natural Language Processing (NLP)\n",
    "    - NLP enables computers to understand, interpret, and respond to human language. With applications in medical research, search engines, and business intelligence, NLP encompasses:  \n",
    "    - **Natural Language Understanding (NLU):** Focused on interpreting input (text or speech) and identifying intents and entities.  \n",
    "    - **Natural Language Generation (NLG):** NLG uses AI to generate written or spoken language from structured data. It includes processes like content analysis, data understanding, and grammatical structuring to produce human-like text. NLG is widely used for news reporting, customer messaging, and business content creation. \n",
    "    - **Applications:**  \n",
    "        - **Interactive Voice Response (IVR):** Enhances customer service through voice-enabled systems.  \n",
    "        - **Chatbots:** Automate customer support using predefined scripts.  \n",
    "        - **Machine Translation:** Automates text translation using AI models.  \n",
    "        - **Conversational Interfaces:** Powers devices like Amazon Alexa and Google Home.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Computational Linguistics\n",
    "    - Computational Linguistics (CL) combines linguistics and computer science to analyze language. Applications include machine translation, speech recognition, text summarization, and building conversational agents. Approaches in CL include:  \n",
    "    - **Corpus-based and Structural Approaches:** Analyze large language datasets.  \n",
    "    - **Interactive Approaches:** Use text or speech inputs to generate responses.  \n",
    "    - **Developmental Approaches:** Mimic language acquisition processes for learning over time.  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Deep Parsing and Tools for NLP}$$\n",
    "\n",
    "- Syntactic Parsing \n",
    "  - Syntax refers to the arrangement of words in sentences.\n",
    "  - Syntax structures define parts of speech and sentence trees.\n",
    "  - Syntax governs how sentences are structured in terms of noun, verb, and prepositional phrases.\n",
    "\n",
    "- Syntactic Structure \n",
    "  - Sentence structure: Subject (NP) + Verb Phrase (VP) + Prepositional Phrase (PP).\n",
    "  - Noun Phrase (NP): Determiner + Noun.\n",
    "  - Verb Phrase (VP): Verb + combinations.\n",
    "  - Prepositional Phrase (PP): Preposition + Noun Phrase.\n",
    "\n",
    "- Examples \n",
    "  - *\"The boy ate the pancakes\"*:\n",
    "    - The boy: NP, ate: Verb, the pancakes: NP.\n",
    "  - *\"The boy ate the pancakes under the door\"*:\n",
    "    - Syntactically correct, contextually incorrect.\n",
    "\n",
    "- Text Syntax Components \n",
    "  - POS tags specify word functions (noun, verb, etc.).\n",
    "  - Dependency grammar captures word relationships in sentences.\n",
    "\n",
    "- Role of a Parser \n",
    "  - A parser checks syntax and builds a structure (e.g., parse tree).\n",
    "  - It splits sentences into subjects and related phrases.\n",
    "\n",
    "\n",
    "- Semantic Parsing \n",
    "  - Converts natural language into machine-understandable meaning.\n",
    "  - Used in machine translation, QA, and code generation.\n",
    "\n",
    "- Example \n",
    "  - *\"The price of bananas increased by 5%\"* ‚Äî words like \"increased\" are predicates, and \"the price of bananas\" is an argument.\n",
    "\n",
    "\n",
    "- Information Extraction \n",
    "  - Extracts relevant info from unstructured data.\n",
    "  - Saves time and reduces human error.\n",
    "  - Uses NLP algorithms for tasks like summarizing, extracting data from websites, etc.\n",
    "\n",
    "- Web Scraping \n",
    "  - Collects raw data from websites using Python tools (e.g., urllib).\n",
    "  - Be mindful of website terms and avoid overloading servers.\n",
    "\n",
    "- Text Summarization \n",
    "  - Summarizes long texts into shorter, informative versions.\n",
    "  - Helps save reading time and improve indexing.\n",
    "\n",
    "  - Summarization Types \n",
    "    - **Input Type**: Single or multi-document.\n",
    "    - **Purpose**: Generic, domain-specific, or query-based.\n",
    "    - **Output**: Extractive or abstractive (generating new sentences).\n",
    "\n",
    "  - TextRank Algorithm \n",
    "    - Extractive summarization based on frequent words in sentences.\n",
    "\n",
    "  - LexRank Algorithm \n",
    "    - Ranks sentences by similarity to others in the text.\n",
    "\n",
    "  - Latent Semantic Analysis (LSA)\n",
    "    - Uses singular value decomposition (SVD) for extractive summarization.\n",
    "\n",
    "  - GPT Transformers \n",
    "    - Abstractive summarization using GPT-2 for generating human-like summaries.\n",
    "\n",
    "\n",
    "- Anaphora Resolution \n",
    "  - Resolves pronouns or noun phrases (e.g., \"He\" refers to \"John\").\n",
    "\n",
    "- Discourse Integration \n",
    "  - Examines how previous sentences affect the current sentence.\n",
    "\n",
    "- Pragmatic Analysis \n",
    "  - Interprets text meaning based on context and cooperation rules.\n",
    "\n",
    "\n",
    "- Ontology in NLP \n",
    "  - Formal representation of domain knowledge (concepts, relationships).\n",
    "  - Enhances understanding of words and sentences.\n",
    "  - Ontology Types \n",
    "    - **Domain-Specific**: Healthcare, finance, etc.\n",
    "    - **General-Purpose**: Common concepts.\n",
    "    - **Upper Ontologies**: Frameworks for specific ontologies.\n",
    "\n",
    "- Benefits of Ontologies \n",
    "  - Improves accuracy and disambiguation.\n",
    "  - Facilitates information sharing and scalability.\n",
    "  - Web Ontology Language (OWL)\n",
    "    - Represents knowledge in machine-readable format (e.g., for e-commerce, healthcare, and research)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 20px;\n",
    "    font-weight: bold;\n",
    "    text-align: center;\">\n",
    "  Basic Python\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average age :  27.33\n",
      "Average age :  27.33\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "sent = 'They told that their ages are 25 26 and 31 respectively.'\n",
    "\n",
    "#Find the average ages in the sentence\n",
    "ar = [int(i) for i in re.findall('\\d{2,3}', sent)]\n",
    "print(f'Average age : {sum(ar)/len(ar) : .2f}')\n",
    "\n",
    "ar=[int(i) for i in sent.split(\" \") if i.isdigit()]\n",
    "print(f'Average age : {sum(ar)/len(ar) : .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§Ö‡§ú‡§Ø\n",
      "‡§Ö‡§§‡•Å‡§≤\n",
      "‡§Ö‡§ú‡§Ø ‡§µ‡§ø‡§ú‡§Ø ‡§™‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§Ö‡§§‡•Å‡§≤\n",
      "‡§Ö‡§ú‡§Ø\n",
      "6\n",
      "‡•Å "
     ]
    }
   ],
   "source": [
    "names = ['‡§Ö‡§ú‡§Ø', '‡§µ‡§ø‡§ú‡§Ø', '‡§™‡•ç‡§∞‡§ø‡§Ø‡§æ', '‡§Ö‡§§‡•Å‡§≤' ] \n",
    "for name in names:\n",
    "    if name.startswith('‡§Ö'):\n",
    "        print(name)\n",
    "\n",
    "print(' '.join(names))\n",
    "\n",
    "print('‡§µ‡§ø‡§ú‡§Ø'.replace('‡§µ‡§ø', '‡§Ö'))\n",
    "\n",
    "print(len(names[2]))\n",
    "\n",
    "for i in name[2]:\n",
    "    print(i, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('names.txt','w', encoding='utf8')\n",
    "for x in range(10):\n",
    "    f.write('‡§™‡•ç‡§∞‡§ø‡§Ø‡§æ\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 2352, 49, '‡§∞', 2351)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('r'),ord('‡§∞'), ord('1'), chr(2352), ord('‡§Ø')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§π‡§™'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '\\u0939\\u092A'\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65039"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'üòä‚ù§Ô∏èüòçüëçüòé'\n",
    "ord(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2346 2325 2379 2337 2366 "
     ]
    }
   ],
   "source": [
    "for x in '‡§™‡§ï‡•ã‡§°‡§æ':\n",
    "    print(ord(x), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 24px;\n",
    "    font-weight: bold;\n",
    "    text-align: center;\">\n",
    "  Tokenization\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall numpy scipy -y\n",
    "# !pip install numpy==1.26.4 scipy==1.11.3\n",
    "## !pip install --force-reinstall numpy==1.26.4 scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package indian to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')                                # tokenizer\n",
    "nltk.download('stopwords')                            # collection of stopwords\n",
    "nltk.download('wordnet')                              # wordnet -> database of english words\n",
    "nltk.download('omw-1.4')                              # open multilingual wordnet\n",
    "nltk.download('averaged_perceptron_tagger')           # POS Tagger\n",
    "nltk.download('indian')                               # indian language POS tagger\n",
    "nltk.download('maxent_ne_chunker')                    # maxent chunking\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 20px;\n",
    "    font-weight: bold;\n",
    "    text-align: center;\">\n",
    "  Word Tokenization\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['They', 'told', 'that', 'their', 'ages', 'of', 'mr.', 'are', '25,', '26.2', 'and', '31', 'respectively.']\n",
      "['They', 'told', 'that', 'their', 'ages', 'of', 'mr.', 'are', '25', ',', '26.2', 'and', '31', 'respectively', '.']\n"
     ]
    }
   ],
   "source": [
    "sent = 'They told that their ages of mr. are 25, 26.2 and 31 respectively.'\n",
    "print(sent.split())\n",
    "print(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'friends!', 'How', 'are', 'you?', 'Welcome', 'to', 'the', 'world', 'of', 'python', 'programming.']\n",
      "['Hello', 'friends', '!', 'How', 'are', 'you', '?', 'Welcome', 'to', 'the', 'world', 'of', 'python', 'programming', '.']\n",
      "Percentage of punctuation 20.0%\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "sent = '''Hello friends!\n",
    "How are you? Welcome to the world of python programming.'''\n",
    "\n",
    "print(sent.split())\n",
    "print(word_tokenize(sent))\n",
    "\n",
    "ar = [1 if i in punctuation else 0 for i in word_tokenize(sent)]\n",
    "ar = sum(ar)/len(ar)\n",
    "\n",
    "print(f\"Percentage of punctuation {ar*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "  -webkit-background-clip: text;\n",
    "  -webkit-text-fill-color: transparent;\n",
    "  font-size: 20px;\n",
    "  font-weight: bold;\n",
    "  text-align: center;\"\n",
    ">\n",
    "  Other Tokenizers\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‡§õ‡§§‡•ç‡§∞‡§™‡§§‡§ø',\n",
       " '‡§∂‡§ø‡§µ‡§æ‡§ú‡•Ä',\n",
       " '‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú',\n",
       " '‡§µ‡§∏‡•ç‡§§‡•Å',\n",
       " '‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π‡§æ‡§≤‡§Ø',\n",
       " '‡§Æ‡•Å‡§Ç‡§¨‡§à',\n",
       " ',',\n",
       " '(',\n",
       " '‡§™‡•Ç‡§∞‡•ç‡§µ',\n",
       " '‡§®‡§æ‡§Æ',\n",
       " \"'The\",\n",
       " 'Prince',\n",
       " 'of',\n",
       " 'Wales',\n",
       " 'Museum',\n",
       " 'of',\n",
       " 'Western',\n",
       " 'India',\n",
       " \"'\",\n",
       " ')',\n",
       " '‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à',\n",
       " '‡§ï‡§æ',\n",
       " '‡§Æ‡•Å‡§ñ‡•ç‡§Ø',\n",
       " '‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π‡§æ‡§≤‡§Ø',\n",
       " '‡§π‡•à‡•§',\n",
       " '‡§á‡§∏‡§ï‡§æ',\n",
       " '‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£',\n",
       " '‡§µ‡•á‡§≤‡•ç‡§∏',\n",
       " '‡§ï‡•á',\n",
       " '‡§∞‡§æ‡§ú‡§ï‡•Å‡§Æ‡§æ‡§∞',\n",
       " '‡§ï‡•á',\n",
       " '‡§≠‡§æ‡§∞‡§§',\n",
       " '‡§Ø‡§æ‡§§‡•ç‡§∞‡§æ',\n",
       " '‡§ï‡•á',\n",
       " '‡§∏‡§Æ‡§Ø',\n",
       " '‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à',\n",
       " '‡§ï‡•á',\n",
       " '‡§™‡•ç‡§∞‡§§‡§ø‡§∑‡•ç‡§†‡§ø‡§§',\n",
       " '‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó‡§™‡§§‡§ø‡§Ø‡•ã',\n",
       " '‡§î‡§∞',\n",
       " '‡§®‡§æ‡§ó‡§∞‡§ø‡§ï‡•ã‡§Ç',\n",
       " '‡§∏‡•á',\n",
       " '‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§',\n",
       " '‡§∏‡§π‡§æ‡§Ø‡§§‡§æ',\n",
       " '‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à',\n",
       " '‡§ï‡•á',\n",
       " '‡§∏‡§∞‡§ï‡§æ‡§∞',\n",
       " '‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ',\n",
       " '‡§∏‡•ç‡§Æ‡§æ‡§∞‡§ï',\n",
       " '‡§ï‡•á',\n",
       " '‡§∞‡•Ç‡§™',\n",
       " '‡§Æ‡•á‡§Ç',\n",
       " '‡§®‡§ø‡§∞‡•ç‡§Æ‡§ø‡§§',\n",
       " '‡§ï‡§ø‡§Ø‡§æ',\n",
       " '‡§ó‡§Ø‡§æ',\n",
       " '‡§•‡§æ‡•§',\n",
       " '‡§Ø‡§π',\n",
       " '‡§≠‡§µ‡•ç‡§Ø',\n",
       " '‡§≠‡§µ‡§®',\n",
       " '‡§¶‡§ï‡•ç‡§∑‡§ø‡§£',\n",
       " '‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à',\n",
       " '‡§ï‡•á',\n",
       " '‡§´‡•ã‡§∞‡•ç‡§ü',\n",
       " '‡§µ‡§ø‡§≤‡§ø‡§Ø‡§Æ',\n",
       " '‡§Æ‡•á',\n",
       " ',',\n",
       " '‡§è‡§≤‡•ç‡§´‡§ø‡§Ç‡§∏‡•ç‡§ü‡§®',\n",
       " '‡§ï‡§æ‡§≤‡•á‡§ú',\n",
       " '‡§ï‡•á',\n",
       " '‡§∏‡§æ‡§Æ‡§®‡•á',\n",
       " '‡§π‡•à‡•§',\n",
       " '‡§á‡§∏‡§ï‡•á',\n",
       " '‡§∏‡§æ‡§Æ‡§®‡•á',\n",
       " '‡§∞‡•Ä‡§ó‡§≤',\n",
       " '‡§∏‡§ø‡§®‡§ø‡§Æ‡§æ',\n",
       " '‡§î‡§∞',\n",
       " '‡§™‡•Å‡§≤‡§ø‡§∏',\n",
       " '‡§Ü‡§Ø‡•Å‡§ï‡•ç‡§§',\n",
       " '‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø',\n",
       " '‡§∏‡•ç‡§•‡§ø‡§§',\n",
       " '‡§π‡•à‡•§',\n",
       " '‡§¨‡§ó‡§≤',\n",
       " '‡§Æ‡•á',\n",
       " \"'\",\n",
       " '‡§°‡•Ö‡§µ‡§ø‡§°',\n",
       " '‡§∏‡§∏‡•Ç‡§®',\n",
       " '‡§™‡•Å‡§∏‡•ç‡§§‡§ï',\n",
       " '‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π‡§æ‡§≤‡§Ø',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " '‡§µ‡•ç‡§Ø‡§æ‡§ü‡•ç‡§∏‡•ç‡§®',\n",
       " '‡§π‡•â‡§ü‡•á‡§≤‡•ç',\n",
       " \"'\",\n",
       " ',',\n",
       " '‡§≠‡•Ä',\n",
       " '‡§π‡•à‡•§',\n",
       " '‡§Ü‡§ó‡•á',\n",
       " '‡§∏‡§Æ‡•Å‡§¶‡•ç‡§∞',\n",
       " '‡§ï‡•á',\n",
       " '‡§§‡§∞‡§´',\n",
       " '‡§ú‡§æ‡§®‡•á',\n",
       " '‡§™‡§∞',\n",
       " \"'\",\n",
       " '‡§ó‡•á‡§ü‡§µ‡•á',\n",
       " '‡§ë‡§´‡§º',\n",
       " '‡§á‡§®‡•ç‡§°‡§ø‡§Ø‡§æ',\n",
       " \"'\",\n",
       " '‡§Ü‡§§‡§æ',\n",
       " '‡§π‡•à‡•§']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = '''\n",
    "‡§õ‡§§‡•ç‡§∞‡§™‡§§‡§ø ‡§∂‡§ø‡§µ‡§æ‡§ú‡•Ä ‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú ‡§µ‡§∏‡•ç‡§§‡•Å ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π‡§æ‡§≤‡§Ø ‡§Æ‡•Å‡§Ç‡§¨‡§à, (‡§™‡•Ç‡§∞‡•ç‡§µ ‡§®‡§æ‡§Æ 'The Prince of Wales Museum of Western India') ‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à ‡§ï‡§æ ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π‡§æ‡§≤‡§Ø ‡§π‡•à‡•§ \n",
    "‡§á‡§∏‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§µ‡•á‡§≤‡•ç‡§∏ ‡§ï‡•á ‡§∞‡§æ‡§ú‡§ï‡•Å‡§Æ‡§æ‡§∞ ‡§ï‡•á ‡§≠‡§æ‡§∞‡§§ ‡§Ø‡§æ‡§§‡•ç‡§∞‡§æ ‡§ï‡•á ‡§∏‡§Æ‡§Ø ‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à ‡§ï‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§∑‡•ç‡§†‡§ø‡§§ ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó‡§™‡§§‡§ø‡§Ø‡•ã ‡§î‡§∞ ‡§®‡§æ‡§ó‡§∞‡§ø‡§ï‡•ã‡§Ç ‡§∏‡•á ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à ‡§ï‡•á ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§∏‡•ç‡§Æ‡§æ‡§∞‡§ï ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§∞‡•ç‡§Æ‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ‡•§ \n",
    "‡§Ø‡§π ‡§≠‡§µ‡•ç‡§Ø ‡§≠‡§µ‡§® ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£ ‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à ‡§ï‡•á ‡§´‡•ã‡§∞‡•ç‡§ü ‡§µ‡§ø‡§≤‡§ø‡§Ø‡§Æ ‡§Æ‡•á, ‡§è‡§≤‡•ç‡§´‡§ø‡§Ç‡§∏‡•ç‡§ü‡§® ‡§ï‡§æ‡§≤‡•á‡§ú ‡§ï‡•á ‡§∏‡§æ‡§Æ‡§®‡•á ‡§π‡•à‡•§ \n",
    "‡§á‡§∏‡§ï‡•á ‡§∏‡§æ‡§Æ‡§®‡•á ‡§∞‡•Ä‡§ó‡§≤ ‡§∏‡§ø‡§®‡§ø‡§Æ‡§æ ‡§î‡§∞ ‡§™‡•Å‡§≤‡§ø‡§∏ ‡§Ü‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§∏‡•ç‡§•‡§ø‡§§ ‡§π‡•à‡•§\n",
    "‡§¨‡§ó‡§≤ ‡§Æ‡•á '‡§°‡•Ö‡§µ‡§ø‡§° ‡§∏‡§∏‡•Ç‡§® ‡§™‡•Å‡§∏‡•ç‡§§‡§ï ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π‡§æ‡§≤‡§Ø', '‡§µ‡•ç‡§Ø‡§æ‡§ü‡•ç‡§∏‡•ç‡§® ‡§π‡•â‡§ü‡•á‡§≤‡•ç', ‡§≠‡•Ä ‡§π‡•à‡•§ \n",
    "‡§Ü‡§ó‡•á ‡§∏‡§Æ‡•Å‡§¶‡•ç‡§∞ ‡§ï‡•á ‡§§‡§∞‡§´ ‡§ú‡§æ‡§®‡•á ‡§™‡§∞ '‡§ó‡•á‡§ü‡§µ‡•á ‡§ë‡§´‡§º ‡§á‡§®‡•ç‡§°‡§ø‡§Ø‡§æ' ‡§Ü‡§§‡§æ ‡§π‡•à‡•§\n",
    "'''\n",
    "\n",
    "word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['„É†„É≥„Éê„Ç§„ÅÆ„ÉÅ„É£„Éà„É©„Éë„ÉÜ„Ç£',\n",
       " '„Ç∑„É¥„Ç°„Éº„Ç∏„Éº',\n",
       " '„Éû„Éè„É©„Ç∏ÂçöÁâ©È§®',\n",
       " '(',\n",
       " '‰ª•Ââç„ÅØ„ÄåË•ø„Ç§„É≥„Éâ„ÅÆ„Éó„É™„É≥„Çπ',\n",
       " '„Ç™„Éñ',\n",
       " '„Ç¶„Çß„Éº„É´„Ç∫ÂçöÁâ©È§®„Äç„Å®„Åó„Å¶Áü•„Çâ„Çå„Å¶„ÅÑ„Åæ„Åó„Åü',\n",
       " ')',\n",
       " '„ÅØ„ÄÅ„É†„É≥„Éê„Ç§„ÅÆ‰∏ªË¶Å„Å™ÂçöÁâ©È§®„Åß„Åô„ÄÇ',\n",
       " '„Åì„ÅÆË®òÂøµÁ¢ë„ÅØ„ÄÅ„Ç¶„Çß„Éº„É´„Ç∫ÁöáÂ§™Â≠ê„ÅÆ„Ç§„É≥„ÉâË®™Âïè‰∏≠„Å´„É†„É≥„Éê„Ç§ÊîøÂ∫ú„ÅåËëóÂêç„Å™ÂÆüÊ•≠ÂÆ∂„ÇÑ„É†„É≥„Éê„Ç§Â∏ÇÊ∞ë„ÅÆÂçîÂäõ„ÇíÂæó„Å¶Ë®òÂøµÁ¢ë„Å®„Åó„Å¶Âª∫„Å¶„Åü„ÇÇ„ÅÆ„Åß„Åô„ÄÇ',\n",
       " '„Åì„ÅÆÂ£ÆÂ§ß„Å™Âª∫Áâ©„ÅØ„ÄÅÂçó„É†„É≥„Éê„Ç§„ÅÆ„Éï„Ç©„Éº„Éà',\n",
       " '„Ç¶„Ç£„É™„Ç¢„É†„ÄÅ„Ç®„É´„Éï„Ç£„É≥„Çπ„Éà„Éº„É≥Â§ßÂ≠¶„ÅÆÂêë„Åã„ÅÑ„Å´„ÅÇ„Çä„Åæ„Åô„ÄÇ',\n",
       " '„É™„Éº„Ç¨„É´„Ç∑„Éç„Éû„Å®Ë≠¶ÂØüÂ∫ÅËàé„ÅåÁõÆ„ÅÆÂâç„Å´„ÅÇ„Çä„Åæ„Åô„ÄÇ',\n",
       " 'Ëøë„Åè„Å´„ÅØ„Äå„Éá„É¥„Ç£„ÉÉ„Éâ„Éª„Çµ„Çπ„Éº„É≥„Éª„Éñ„ÉÉ„ÇØ„Éª„Éü„É•„Éº„Ç∏„Ç¢„É†„Äç„ÄÅ„Äå„É¥„É£„Éà„É≥„Éª„Éõ„ÉÜ„É´„Äç„ÇÇ„ÅÇ„Çä„Åæ„Åô„ÄÇ',\n",
       " '„Åï„Çâ„Å´Êµ∑„ÅÆ„Åª„ÅÜ„Å∏Ë°å„Åè„Å®„Äå„Ç§„É≥„ÉâÈñÄ„Äç„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"\"\"\n",
    "„É†„É≥„Éê„Ç§„ÅÆ„ÉÅ„É£„Éà„É©„Éë„ÉÜ„Ç£ „Ç∑„É¥„Ç°„Éº„Ç∏„Éº „Éû„Éè„É©„Ç∏ÂçöÁâ©È§® (‰ª•Ââç„ÅØ„ÄåË•ø„Ç§„É≥„Éâ„ÅÆ„Éó„É™„É≥„Çπ „Ç™„Éñ „Ç¶„Çß„Éº„É´„Ç∫ÂçöÁâ©È§®„Äç„Å®„Åó„Å¶Áü•„Çâ„Çå„Å¶„ÅÑ„Åæ„Åó„Åü) „ÅØ„ÄÅ„É†„É≥„Éê„Ç§„ÅÆ‰∏ªË¶Å„Å™ÂçöÁâ©È§®„Åß„Åô„ÄÇ\n",
    "„Åì„ÅÆË®òÂøµÁ¢ë„ÅØ„ÄÅ„Ç¶„Çß„Éº„É´„Ç∫ÁöáÂ§™Â≠ê„ÅÆ„Ç§„É≥„ÉâË®™Âïè‰∏≠„Å´„É†„É≥„Éê„Ç§ÊîøÂ∫ú„ÅåËëóÂêç„Å™ÂÆüÊ•≠ÂÆ∂„ÇÑ„É†„É≥„Éê„Ç§Â∏ÇÊ∞ë„ÅÆÂçîÂäõ„ÇíÂæó„Å¶Ë®òÂøµÁ¢ë„Å®„Åó„Å¶Âª∫„Å¶„Åü„ÇÇ„ÅÆ„Åß„Åô„ÄÇ\n",
    "„Åì„ÅÆÂ£ÆÂ§ß„Å™Âª∫Áâ©„ÅØ„ÄÅÂçó„É†„É≥„Éê„Ç§„ÅÆ„Éï„Ç©„Éº„Éà „Ç¶„Ç£„É™„Ç¢„É†„ÄÅ„Ç®„É´„Éï„Ç£„É≥„Çπ„Éà„Éº„É≥Â§ßÂ≠¶„ÅÆÂêë„Åã„ÅÑ„Å´„ÅÇ„Çä„Åæ„Åô„ÄÇ\n",
    "„É™„Éº„Ç¨„É´„Ç∑„Éç„Éû„Å®Ë≠¶ÂØüÂ∫ÅËàé„ÅåÁõÆ„ÅÆÂâç„Å´„ÅÇ„Çä„Åæ„Åô„ÄÇ\n",
    "Ëøë„Åè„Å´„ÅØ„Äå„Éá„É¥„Ç£„ÉÉ„Éâ„Éª„Çµ„Çπ„Éº„É≥„Éª„Éñ„ÉÉ„ÇØ„Éª„Éü„É•„Éº„Ç∏„Ç¢„É†„Äç„ÄÅ„Äå„É¥„É£„Éà„É≥„Éª„Éõ„ÉÜ„É´„Äç„ÇÇ„ÅÇ„Çä„Åæ„Åô„ÄÇ\n",
    "„Åï„Çâ„Å´Êµ∑„ÅÆ„Åª„ÅÜ„Å∏Ë°å„Åè„Å®„Äå„Ç§„É≥„ÉâÈñÄ„Äç„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ\"\"\"\n",
    "\n",
    "word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "  -webkit-background-clip: text;\n",
    "  -webkit-text-fill-color: transparent;\n",
    "  font-size: 20px;\n",
    "  font-weight: bold;\n",
    "  text-align: center;\"\n",
    ">\n",
    "  Senetence Tokenizers\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello friends!',\n",
       " 'How are you?',\n",
       " 'Welcome to the world of python programming.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = '''Hello friends!\n",
    "How are you? Welcome to the world of python programming.'''\n",
    "\n",
    "sent_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\n‡§õ‡§§‡•ç‡§∞‡§™‡§§‡§ø ‡§∂‡§ø‡§µ‡§æ‡§ú‡•Ä ‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú ‡§µ‡§∏‡•ç‡§§‡•Å ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π‡§æ‡§≤‡§Ø ‡§Æ‡•Å‡§Ç‡§¨‡§à, (‡§™‡•Ç‡§∞‡•ç‡§µ ‡§®‡§æ‡§Æ 'The Prince of Wales Museum of Western India') ‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à ‡§ï‡§æ ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π‡§æ‡§≤‡§Ø ‡§π‡•à.\",\n",
       " '‡§á‡§∏‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§µ‡•á‡§≤‡•ç‡§∏ ‡§ï‡•á ‡§∞‡§æ‡§ú‡§ï‡•Å‡§Æ‡§æ‡§∞ ‡§ï‡•á ‡§≠‡§æ‡§∞‡§§ ‡§Ø‡§æ‡§§‡•ç‡§∞‡§æ ‡§ï‡•á ‡§∏‡§Æ‡§Ø ‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à ‡§ï‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§∑‡•ç‡§†‡§ø‡§§ ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó‡§™‡§§‡§ø‡§Ø‡•ã ‡§î‡§∞ ‡§®‡§æ‡§ó‡§∞‡§ø‡§ï‡•ã‡§Ç ‡§∏‡•á ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à ‡§ï‡•á ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§∏‡•ç‡§Æ‡§æ‡§∞‡§ï ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§∞‡•ç‡§Æ‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ.',\n",
       " '‡§Ø‡§π ‡§≠‡§µ‡•ç‡§Ø ‡§≠‡§µ‡§® ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£ ‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à ‡§ï‡•á ‡§´‡•ã‡§∞‡•ç‡§ü ‡§µ‡§ø‡§≤‡§ø‡§Ø‡§Æ ‡§Æ‡•á, ‡§è‡§≤‡•ç‡§´‡§ø‡§Ç‡§∏‡•ç‡§ü‡§® ‡§ï‡§æ‡§≤‡•á‡§ú ‡§ï‡•á ‡§∏‡§æ‡§Æ‡§®‡•á ‡§π‡•à.',\n",
       " '‡§á‡§∏‡§ï‡•á ‡§∏‡§æ‡§Æ‡§®‡•á ‡§∞‡•Ä‡§ó‡§≤ ‡§∏‡§ø‡§®‡§ø‡§Æ‡§æ ‡§î‡§∞ ‡§™‡•Å‡§≤‡§ø‡§∏ ‡§Ü‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§∏‡•ç‡§•‡§ø‡§§ ‡§π‡•à.',\n",
       " \"‡§¨‡§ó‡§≤ ‡§Æ‡•á '‡§°‡•Ö‡§µ‡§ø‡§° ‡§∏‡§∏‡•Ç‡§® ‡§™‡•Å‡§∏‡•ç‡§§‡§ï ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π‡§æ‡§≤‡§Ø', '‡§µ‡•ç‡§Ø‡§æ‡§ü‡•ç‡§∏‡•ç‡§® ‡§π‡•â‡§ü‡•á‡§≤‡•ç', ‡§≠‡•Ä ‡§π‡•à.\",\n",
       " \"‡§Ü‡§ó‡•á ‡§∏‡§Æ‡•Å‡§¶‡•ç‡§∞ ‡§ï‡•á ‡§§‡§∞‡§´ ‡§ú‡§æ‡§®‡•á ‡§™‡§∞ '‡§ó‡•á‡§ü‡§µ‡•á ‡§ë‡§´‡§º ‡§á‡§®‡•ç‡§°‡§ø‡§Ø‡§æ' ‡§Ü‡§§‡§æ ‡§π‡•à.\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = '''\n",
    "‡§õ‡§§‡•ç‡§∞‡§™‡§§‡§ø ‡§∂‡§ø‡§µ‡§æ‡§ú‡•Ä ‡§Æ‡§π‡§æ‡§∞‡§æ‡§ú ‡§µ‡§∏‡•ç‡§§‡•Å ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π‡§æ‡§≤‡§Ø ‡§Æ‡•Å‡§Ç‡§¨‡§à, (‡§™‡•Ç‡§∞‡•ç‡§µ ‡§®‡§æ‡§Æ 'The Prince of Wales Museum of Western India') ‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à ‡§ï‡§æ ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π‡§æ‡§≤‡§Ø ‡§π‡•à.\n",
    "‡§á‡§∏‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§µ‡•á‡§≤‡•ç‡§∏ ‡§ï‡•á ‡§∞‡§æ‡§ú‡§ï‡•Å‡§Æ‡§æ‡§∞ ‡§ï‡•á ‡§≠‡§æ‡§∞‡§§ ‡§Ø‡§æ‡§§‡•ç‡§∞‡§æ ‡§ï‡•á ‡§∏‡§Æ‡§Ø ‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à ‡§ï‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§∑‡•ç‡§†‡§ø‡§§ ‡§â‡§¶‡•ç‡§Ø‡•ã‡§ó‡§™‡§§‡§ø‡§Ø‡•ã ‡§î‡§∞ ‡§®‡§æ‡§ó‡§∞‡§ø‡§ï‡•ã‡§Ç ‡§∏‡•á ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à ‡§ï‡•á ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§∏‡•ç‡§Æ‡§æ‡§∞‡§ï ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§∞‡•ç‡§Æ‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ.\n",
    "‡§Ø‡§π ‡§≠‡§µ‡•ç‡§Ø ‡§≠‡§µ‡§® ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£ ‡§Æ‡•Å‡§Æ‡•ç‡§¨‡§à ‡§ï‡•á ‡§´‡•ã‡§∞‡•ç‡§ü ‡§µ‡§ø‡§≤‡§ø‡§Ø‡§Æ ‡§Æ‡•á, ‡§è‡§≤‡•ç‡§´‡§ø‡§Ç‡§∏‡•ç‡§ü‡§® ‡§ï‡§æ‡§≤‡•á‡§ú ‡§ï‡•á ‡§∏‡§æ‡§Æ‡§®‡•á ‡§π‡•à.\n",
    "‡§á‡§∏‡§ï‡•á ‡§∏‡§æ‡§Æ‡§®‡•á ‡§∞‡•Ä‡§ó‡§≤ ‡§∏‡§ø‡§®‡§ø‡§Æ‡§æ ‡§î‡§∞ ‡§™‡•Å‡§≤‡§ø‡§∏ ‡§Ü‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§∏‡•ç‡§•‡§ø‡§§ ‡§π‡•à.\n",
    "‡§¨‡§ó‡§≤ ‡§Æ‡•á '‡§°‡•Ö‡§µ‡§ø‡§° ‡§∏‡§∏‡•Ç‡§® ‡§™‡•Å‡§∏‡•ç‡§§‡§ï ‡§∏‡§Ç‡§ó‡•ç‡§∞‡§π‡§æ‡§≤‡§Ø', '‡§µ‡•ç‡§Ø‡§æ‡§ü‡•ç‡§∏‡•ç‡§® ‡§π‡•â‡§ü‡•á‡§≤‡•ç', ‡§≠‡•Ä ‡§π‡•à. \n",
    "‡§Ü‡§ó‡•á ‡§∏‡§Æ‡•Å‡§¶‡•ç‡§∞ ‡§ï‡•á ‡§§‡§∞‡§´ ‡§ú‡§æ‡§®‡•á ‡§™‡§∞ '‡§ó‡•á‡§ü‡§µ‡•á ‡§ë‡§´‡§º ‡§á‡§®‡•ç‡§°‡§ø‡§Ø‡§æ' ‡§Ü‡§§‡§æ ‡§π‡•à.\n",
    "'''\n",
    "\n",
    "sent_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the max sentence which has the most the word 'the'\n",
    "sent = \"\"\"India, officially the Republic of India,[j][20] is a country in South Asia. It is the seventh-largest country in the world by area and the most populous country. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[k] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand, Myanmar, and Indonesia.\n",
    "\n",
    "Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago.[22][23][24] Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, second only to Africa in human genetic diversity.[25] Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE.[26] By at least 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest.[27][28] Its evidence today is found in the hymns of the Rigveda. Preserved by an oral tradition that was resolutely vigilant, the Rigveda records the dawning of Hinduism in India.[29] The Dravidian languages of India were supplanted in the northern and western regions.[30] By 400 BCE, stratification and exclusion by caste had emerged within Hinduism,[31] and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity.[32] Early political consolidations gave rise to the loose-knit Maurya and Gupta Empires based in the Ganges Basin.[33] Their collective era was suffused with wide-ranging creativity,[34] but also marked by the declining status of women,[35] and the incorporation of untouchability into an organised system of belief.[l][36] The Middle kingdoms exported Sanskrit language, south Indian scripts and religions of Hinduism and Buddhism to the Southeast Asia.\n",
    "\"\"\"\n",
    "sents = sent_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[k] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = {i : j.lower().count('the')  for i,j in enumerate(sents)}\n",
    "\n",
    "idex = sorted(res.items(), key=lambda x: x[1], reverse=True)\n",
    "display(idex[0][1], sents[idex[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[k] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(\n",
    "    lambda x, y : x if (x.lower().count('the') > y.lower().count('the')) else y,\n",
    "    sents\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "  -webkit-background-clip: text;\n",
    "  -webkit-text-fill-color: transparent;\n",
    "  font-size: 20px;\n",
    "  font-weight: bold;\n",
    "  text-align: center;\"\n",
    ">\n",
    "  Whitespace Tokenizers\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'python',\n",
       " 'programming.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent = '''Hello friends!\n",
    "How are you? Welcome to the world of python programming.'''\n",
    "tk = WhitespaceTokenizer()\n",
    "\n",
    "\n",
    "display(tk.tokenize(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "  -webkit-background-clip: text;\n",
    "  -webkit-text-fill-color: transparent;\n",
    "  font-size: 20px;\n",
    "  font-weight: bold;\n",
    "  text-align: center;\"\n",
    ">\n",
    "Space Tokenizers\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import SpaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends!\\nHow',\n",
       " 'are',\n",
       " 'you?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'python',\n",
       " 'programming.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends!\\nHow',\n",
       " 'are',\n",
       " 'you?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'python',\n",
       " 'programming.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent = '''Hello friends!\n",
    "How are you? Welcome to the world of python programming.'''\n",
    "\n",
    "\n",
    "# Only take spaces not the newline\n",
    "tk = SpaceTokenizer()\n",
    "\n",
    "display(sent.split(' '))\n",
    "display(tk.tokenize(sent)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "  -webkit-background-clip: text;\n",
    "  -webkit-text-fill-color: transparent;\n",
    "  font-size: 20px;\n",
    "  font-weight: bold;\n",
    "  text-align: center;\"\n",
    ">\n",
    "Line Tokenizers\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import LineTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello friends!', 'How are you? Welcome to the world of python programming.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Hello friends!', 'How are you? Welcome to the world of python programming.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent = '''Hello friends!\n",
    "How are you? Welcome to the world of python programming.'''\n",
    "\n",
    "\n",
    "# Only take newline\n",
    "tk = LineTokenizer()\n",
    "\n",
    "display(sent.split('\\n'))\n",
    "display(tk.tokenize(sent)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "  -webkit-background-clip: text;\n",
    "  -webkit-text-fill-color: transparent;\n",
    "  font-size: 20px;\n",
    "  font-weight: bold;\n",
    "  text-align: center;\"\n",
    ">\n",
    "Tab Tokenizers\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TabTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello friends!\\nHow are you? Welcome to',\n",
       " 'the world of python',\n",
       " 'programming.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Hello friends!\\nHow are you? Welcome to',\n",
       " 'the world of python',\n",
       " 'programming.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent = '''Hello friends!\n",
    "How are you? Welcome to\\tthe world of python\\tprogramming.'''\n",
    "\n",
    "\n",
    "# Only take tab\n",
    "tk = TabTokenizer()\n",
    "\n",
    "display(sent.split('\\t'))\n",
    "display(tk.tokenize(sent)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "  -webkit-background-clip: text;\n",
    "  -webkit-text-fill-color: transparent;\n",
    "  font-size: 20px;\n",
    "  font-weight: bold;\n",
    "  text-align: center;\"\n",
    ">\n",
    "Tweet Tokenizers\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'ü´£',\n",
       " 'friends',\n",
       " '!',\n",
       " ':',\n",
       " ')',\n",
       " 'üíÄ',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " ':',\n",
       " '$',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'pythonüêç',\n",
       " 'programming.',\n",
       " '<',\n",
       " '3']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'ü´£',\n",
       " 'friends',\n",
       " '!',\n",
       " ':)',\n",
       " 'üíÄ',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " ':',\n",
       " '$',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'python',\n",
       " 'üêç',\n",
       " 'programming',\n",
       " '.',\n",
       " '<3']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent = '''Hello ü´£ friends!:)üíÄ\n",
    "How are you? Welcome :$ to\\tthe world of pythonüêç\\tprogramming.<3'''\n",
    "\n",
    "tk = TweetTokenizer()\n",
    "# It tokenizes based on the emojis and emoji generator keycombinations( :) smile, :( sad face, <3 heart, etc )\n",
    " \n",
    "display(word_tokenize(sent))\n",
    "display(tk.tokenize(sent)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "  -webkit-background-clip: text;\n",
    "  -webkit-text-fill-color: transparent;\n",
    "  font-size: 20px;\n",
    "  font-weight: bold;\n",
    "  text-align: center;\"\n",
    ">\n",
    "Multi Word Extension Tokenizers\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Van Rossom',\n",
       " 'is',\n",
       " 'in',\n",
       " 'Pune',\n",
       " '.',\n",
       " 'We',\n",
       " 'welcomed',\n",
       " 'Van Rossom',\n",
       " 'here',\n",
       " '.',\n",
       " 'Van',\n",
       " 'Nayak',\n",
       " 'is',\n",
       " 'also',\n",
       " 'in',\n",
       " 'pune',\n",
       " 'doing',\n",
       " 'Majdoori',\n",
       " 'in',\n",
       " 'CDAC']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Van Rossom is in Pune. We welcomed Van Rossom here. Van Nayak is also in pune doing Majdoori in CDAC'\n",
    "\n",
    "# A tokenizer that processes tokenized text and merges multi-word expressions into single tokens.\n",
    "tk = MWETokenizer(separator=' ') \n",
    "\n",
    "tk.add_mwe(('Van', 'Rossom'))\n",
    "tk.tokenize(word_tokenize(sent)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "  -webkit-background-clip: text;\n",
    "  -webkit-text-fill-color: transparent;\n",
    "  font-size: 20px;\n",
    "  font-weight: bold;\n",
    "  text-align: center;\"\n",
    ">\n",
    "Custom Tokenizers\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Van',\n",
       " 'Rossom',\n",
       " 'is',\n",
       " 'in',\n",
       " 'Pune',\n",
       " 'We',\n",
       " 'welcomed',\n",
       " 'Van',\n",
       " 'Rossom',\n",
       " 'here',\n",
       " 'Van',\n",
       " 'Nayak',\n",
       " 'in',\n",
       " '>',\n",
       " 'pune',\n",
       " '&',\n",
       " 'doing',\n",
       " 'Majdoori',\n",
       " 'in',\n",
       " 'CDAC']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent = 'Van Rossom is in Pune. We welcomed Van Rossom here!. Van Nayak in > pune & doing Majdoori in CDAC'\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    return re.split(r\"[.,;?!\\s]+\", text)\n",
    "\n",
    "tokens = custom_tokenizer(sent)\n",
    "display(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
