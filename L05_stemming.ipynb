{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"\n",
        "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
        "    -webkit-background-clip: text;\n",
        "    -webkit-text-fill-color: transparent;\n",
        "    font-size: 20px;\n",
        "    font-weight: bold;\n",
        "    text-align: center;\">\n",
        "  Stemming\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "JYN82LyGdVy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming is the process of reducing a word to its stem that affixes and prefixes ot to the roots of words known as \"lemmas\".\n",
        "\n",
        "Stemming is important in natural language understaingn (NLU) and natual language processing(NLP).\n",
        "\n",
        "Stemming is a part of linguistic studies in morphology as well as artificial intelligence(Ai) information retrieval and extraction."
      ],
      "metadata": {
        "id": "zN7qu0qwdZdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6BjAzyNtI8K",
        "outputId": "84ed70db-bbf3-464b-f9fc-83d77dcc4e5f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words1 = 'managing', 'manage', 'management', 'managerial', 'managed'\n",
        "words2 = 'worked', 'workable', 'working', 'worked'\n",
        "words3 = 'big', 'bigger', 'biggest'\n",
        "words4 = 'go', 'gone', 'went', 'going'\n",
        "words5 = 'association', 'associated', 'associate'"
      ],
      "metadata": {
        "id": "8bm-RviSfK62"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ],
      "metadata": {
        "id": "on2mzah-pkdq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n",
        "ls = LancasterStemmer()\n",
        "ss = SnowballStemmer('english')\n",
        "wnl =  WordNetLemmatizer()\n"
      ],
      "metadata": {
        "id": "qKCOJxSppkbJ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Porter Stemmer\\n\")\n",
        "for words in [ words1, words2, words3, words4, words5]:\n",
        "    for i in words:\n",
        "        print(f'{i:<15} :  {ps.stem(i)}')\n",
        "    print()\n",
        "\n",
        "print(\"Lancaster Stemmer\\n\")\n",
        "for words in [ words1, words2, words3, words4, words5]:\n",
        "    for i in words:\n",
        "        print(f'{i:<15} :  {ls.stem(i)}')\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "print(\"Snowball Stemmer\\n\")\n",
        "for words in [ words1, words2, words3, words4, words5]:\n",
        "    for i in words:\n",
        "        print(f'{i:<15} :  {ss.stem(i)}')\n",
        "    print()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtCFe4ZmpkYx",
        "outputId": "052e8923-9fab-45bd-d70e-696aa83b34c6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Stemmer\n",
            "\n",
            "managing        :  manag\n",
            "manage          :  manag\n",
            "management      :  manag\n",
            "managerial      :  manageri\n",
            "managed         :  manag\n",
            "\n",
            "worked          :  work\n",
            "workable        :  workabl\n",
            "working         :  work\n",
            "worked          :  work\n",
            "\n",
            "big             :  big\n",
            "bigger          :  bigger\n",
            "biggest         :  biggest\n",
            "\n",
            "go              :  go\n",
            "gone            :  gone\n",
            "went            :  went\n",
            "going           :  go\n",
            "\n",
            "association     :  associ\n",
            "associated      :  associ\n",
            "associate       :  associ\n",
            "\n",
            "Lancaster Stemmer\n",
            "\n",
            "managing        :  man\n",
            "manage          :  man\n",
            "management      :  man\n",
            "managerial      :  man\n",
            "managed         :  man\n",
            "\n",
            "worked          :  work\n",
            "workable        :  work\n",
            "working         :  work\n",
            "worked          :  work\n",
            "\n",
            "big             :  big\n",
            "bigger          :  big\n",
            "biggest         :  biggest\n",
            "\n",
            "go              :  go\n",
            "gone            :  gon\n",
            "went            :  went\n",
            "going           :  going\n",
            "\n",
            "association     :  assocy\n",
            "associated      :  assocy\n",
            "associate       :  assocy\n",
            "\n",
            "Snowball Stemmer\n",
            "\n",
            "managing        :  manag\n",
            "manage          :  manag\n",
            "management      :  manag\n",
            "managerial      :  manageri\n",
            "managed         :  manag\n",
            "\n",
            "worked          :  work\n",
            "workable        :  workabl\n",
            "working         :  work\n",
            "worked          :  work\n",
            "\n",
            "big             :  big\n",
            "bigger          :  bigger\n",
            "biggest         :  biggest\n",
            "\n",
            "go              :  go\n",
            "gone            :  gone\n",
            "went            :  went\n",
            "going           :  go\n",
            "\n",
            "association     :  associ\n",
            "associated      :  associ\n",
            "associate       :  associ\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wnl.lemmatize('players', pos='n'))\n",
        "print(wnl.lemmatize('players', pos='v'))\n",
        "print(wnl.lemmatize('players', pos='a'))\n",
        "print(wnl.lemmatize('players', pos='r'))\n",
        "print('-'*10)\n",
        "print(wnl.lemmatize('playing', pos='n'))\n",
        "print(wnl.lemmatize('playing', pos='v'))\n",
        "print(wnl.lemmatize('playing', pos='a'))\n",
        "print(wnl.lemmatize('playing', pos='r'))\n",
        "print('-'*10)\n",
        "for word in words1:\n",
        "    print('n -> ' , wnl.lemmatize(word, pos='n'))\n",
        "    print('v -> ' , wnl.lemmatize(word, pos='v'))\n",
        "    print('a -> ' , wnl.lemmatize(word, pos='a'))\n",
        "    print('r -> ' , wnl.lemmatize(word, pos='r'))\n",
        "\n",
        "print('-'*10)\n",
        "for word in words2:\n",
        "    print('n -> ' , wnl.lemmatize(word, pos='n'))\n",
        "    print('v -> ' , wnl.lemmatize(word, pos='v'))\n",
        "    print('a -> ' , wnl.lemmatize(word, pos='a'))\n",
        "    print('r -> ' , wnl.lemmatize(word, pos='r'))\n",
        "\n",
        "print('-'*10)\n",
        "for word in words3:\n",
        "    print('n -> ' , wnl.lemmatize(word, pos='n'))\n",
        "    print('v -> ' , wnl.lemmatize(word, pos='v'))\n",
        "    print('a -> ' , wnl.lemmatize(word, pos='a'))\n",
        "    print('r -> ' , wnl.lemmatize(word, pos='r'))\n",
        "\n",
        "print('-'*10)\n",
        "for word in words3:\n",
        "    print('n -> ' , wnl.lemmatize(word, pos='n'))\n",
        "    print('v -> ' , wnl.lemmatize(word, pos='v'))\n",
        "    print('a -> ' , wnl.lemmatize(word, pos='a'))\n",
        "    print('r -> ' , wnl.lemmatize(word, pos='r'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7j0Ta2ezo-8",
        "outputId": "050256c8-0b1c-4325-d274-f8d66c574172"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "player\n",
            "players\n",
            "players\n",
            "players\n",
            "----------\n",
            "playing\n",
            "play\n",
            "playing\n",
            "playing\n",
            "----------\n",
            "n ->  managing\n",
            "v ->  manage\n",
            "a ->  managing\n",
            "r ->  managing\n",
            "n ->  manage\n",
            "v ->  manage\n",
            "a ->  manage\n",
            "r ->  manage\n",
            "n ->  management\n",
            "v ->  management\n",
            "a ->  management\n",
            "r ->  management\n",
            "n ->  managerial\n",
            "v ->  managerial\n",
            "a ->  managerial\n",
            "r ->  managerial\n",
            "n ->  managed\n",
            "v ->  manage\n",
            "a ->  managed\n",
            "r ->  managed\n",
            "----------\n",
            "n ->  worked\n",
            "v ->  work\n",
            "a ->  worked\n",
            "r ->  worked\n",
            "n ->  workable\n",
            "v ->  workable\n",
            "a ->  workable\n",
            "r ->  workable\n",
            "n ->  working\n",
            "v ->  work\n",
            "a ->  working\n",
            "r ->  working\n",
            "n ->  worked\n",
            "v ->  work\n",
            "a ->  worked\n",
            "r ->  worked\n",
            "----------\n",
            "n ->  big\n",
            "v ->  big\n",
            "a ->  big\n",
            "r ->  big\n",
            "n ->  bigger\n",
            "v ->  bigger\n",
            "a ->  big\n",
            "r ->  bigger\n",
            "n ->  biggest\n",
            "v ->  biggest\n",
            "a ->  big\n",
            "r ->  biggest\n",
            "----------\n",
            "n ->  big\n",
            "v ->  big\n",
            "a ->  big\n",
            "r ->  big\n",
            "n ->  bigger\n",
            "v ->  bigger\n",
            "a ->  big\n",
            "r ->  bigger\n",
            "n ->  biggest\n",
            "v ->  biggest\n",
            "a ->  big\n",
            "r ->  biggest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"\n",
        "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
        "    -webkit-background-clip: text;\n",
        "    -webkit-text-fill-color: transparent;\n",
        "    font-size: 20px;\n",
        "    font-weight: bold;\n",
        "    text-align: center;\">\n",
        "  Porter Stemmer\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "WaQ5o3bJuWEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "\n",
        "text = 'Hello friends! How are you? I like Python Programming'\n",
        "\n",
        "# Removing the punctuations\n",
        "token1 = [word for word in word_tokenize(text) if word not in punctuation]\n",
        "display(token1)\n",
        "\n",
        "# Remove stop words\n",
        "swords = stopwords.words('english')\n",
        "token2 = [word for word in token1 if word.lower() not in swords]\n",
        "display(token2)\n",
        "\n",
        "# Stemming the words\n",
        "ps = PorterStemmer()\n",
        "token3 = [(ps.stem(word.lower())) for word in token2]\n",
        "display(token3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "8V8GCFQBsKTc",
        "outputId": "caf9392c-f542-4af8-afe9-e2223c692bb4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['Hello', 'friends', 'How', 'are', 'you', 'I', 'like', 'Python', 'Programming']"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['Hello', 'friends', 'like', 'Python', 'Programming']"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['hello', 'friend', 'like', 'python', 'program']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"\n",
        "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
        "    -webkit-background-clip: text;\n",
        "    -webkit-text-fill-color: transparent;\n",
        "    font-size: 20px;\n",
        "    font-weight: bold;\n",
        "    text-align: center;\">\n",
        "  Lancaster Stemmer\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "vkiph_fruZdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "\n",
        "text = 'Hello friends! How are you? I like Python Programming'\n",
        "\n",
        "# Removing the punctuations\n",
        "token1 = [word for word in word_tokenize(text) if word not in punctuation]\n",
        "display(token1)\n",
        "\n",
        "# Remove stop words\n",
        "swords = stopwords.words('english')\n",
        "token2 = [word for word in token1 if word.lower() not in swords]\n",
        "display(token2)\n",
        "\n",
        "# Stemming the words\n",
        "ls = LancasterStemmer()\n",
        "token3 = [(ls.stem(word.lower())) for word in token2]\n",
        "display(token3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "_jWhYUAiujDP",
        "outputId": "415ebc91-2ea8-4e2c-b8b1-22b53f479690"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['Hello', 'friends', 'How', 'are', 'you', 'I', 'like', 'Python', 'Programming']"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['Hello', 'friends', 'like', 'Python', 'Programming']"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['hello', 'friend', 'lik', 'python', 'program']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"\n",
        "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
        "    -webkit-background-clip: text;\n",
        "    -webkit-text-fill-color: transparent;\n",
        "    font-size: 20px;\n",
        "    font-weight: bold;\n",
        "    text-align: center;\">\n",
        "  Snowball Stemming\n",
        "</div>\n",
        "Oly stemmer which has option to select languages"
      ],
      "metadata": {
        "id": "R7p5GqtsudLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(SnowballStemmer)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXjR1_yuxanB",
        "outputId": "8392771e-7002-4c23-aa98-823b421acff6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class SnowballStemmer in module nltk.stem.snowball:\n",
            "\n",
            "class SnowballStemmer(nltk.stem.api.StemmerI)\n",
            " |  SnowballStemmer(language, ignore_stopwords=False)\n",
            " |  \n",
            " |  Snowball Stemmer\n",
            " |  \n",
            " |  The following languages are supported:\n",
            " |  Arabic, Danish, Dutch, English, Finnish, French, German,\n",
            " |  Hungarian, Italian, Norwegian, Portuguese, Romanian, Russian,\n",
            " |  Spanish and Swedish.\n",
            " |  \n",
            " |  The algorithm for English is documented here:\n",
            " |  \n",
            " |      Porter, M. \"An algorithm for suffix stripping.\"\n",
            " |      Program 14.3 (1980): 130-137.\n",
            " |  \n",
            " |  The algorithms have been developed by Martin Porter.\n",
            " |  These stemmers are called Snowball, because Porter created\n",
            " |  a programming language with this name for creating\n",
            " |  new stemming algorithms. There is more information available\n",
            " |  at http://snowball.tartarus.org/\n",
            " |  \n",
            " |  The stemmer is invoked as shown below:\n",
            " |  \n",
            " |  >>> from nltk.stem import SnowballStemmer # See which languages are supported\n",
            " |  >>> print(\" \".join(SnowballStemmer.languages)) # doctest: +NORMALIZE_WHITESPACE\n",
            " |  arabic danish dutch english finnish french german hungarian\n",
            " |  italian norwegian porter portuguese romanian russian\n",
            " |  spanish swedish\n",
            " |  >>> stemmer = SnowballStemmer(\"german\") # Choose a language\n",
            " |  >>> stemmer.stem(\"Autobahnen\") # Stem a word\n",
            " |  'autobahn'\n",
            " |  \n",
            " |  Invoking the stemmers that way is useful if you do not know the\n",
            " |  language to be stemmed at runtime. Alternatively, if you already know\n",
            " |  the language, then you can invoke the language specific stemmer directly:\n",
            " |  \n",
            " |  >>> from nltk.stem.snowball import GermanStemmer\n",
            " |  >>> stemmer = GermanStemmer()\n",
            " |  >>> stemmer.stem(\"Autobahnen\")\n",
            " |  'autobahn'\n",
            " |  \n",
            " |  :param language: The language whose subclass is instantiated.\n",
            " |  :type language: str or unicode\n",
            " |  :param ignore_stopwords: If set to True, stopwords are\n",
            " |                           not stemmed and returned unchanged.\n",
            " |                           Set to False by default.\n",
            " |  :type ignore_stopwords: bool\n",
            " |  :raise ValueError: If there is no stemmer for the specified\n",
            " |                         language, a ValueError is raised.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      SnowballStemmer\n",
            " |      nltk.stem.api.StemmerI\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, language, ignore_stopwords=False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  stem(self, token)\n",
            " |      Strip affixes from the token and return the stem.\n",
            " |      \n",
            " |      :param token: The token that should be stemmed.\n",
            " |      :type token: str\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  languages = ('arabic', 'danish', 'dutch', 'english', 'finnish', 'frenc...\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from nltk.stem.api.StemmerI:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(SnowballStemmer.languages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JylCPa0Owqgj",
        "outputId": "04880315-5925-4590-df8d-9e1509cd0949"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "\n",
        "text = 'Hello friends! How are you? I like Python Programming'\n",
        "\n",
        "# Removing the punctuations\n",
        "token1 = [word for word in word_tokenize(text) if word not in punctuation]\n",
        "display(token1)\n",
        "\n",
        "# Remove stop words\n",
        "swords = stopwords.words('english')\n",
        "token2 = [word for word in token1 if word.lower() not in swords]\n",
        "display(token2)\n",
        "\n",
        "# Stemming the words\n",
        "ss = SnowballStemmer('english')\n",
        "token3 = [(ss.stem(word.lower())) for word in token2]\n",
        "display(token3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "G7qdvPILurde",
        "outputId": "180ef252-e7ab-44d4-ea16-8a4132d8e0c7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['Hello', 'friends', 'How', 'are', 'you', 'I', 'like', 'Python', 'Programming']"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['Hello', 'friends', 'like', 'Python', 'Programming']"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['hello', 'friend', 'like', 'python', 'program']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"\n",
        "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
        "    -webkit-background-clip: text;\n",
        "    -webkit-text-fill-color: transparent;\n",
        "    font-size: 20px;\n",
        "    font-weight: bold;\n",
        "    text-align: center;\">\n",
        "  Lemmatiser Stemming\n",
        "</div>\n",
        "\n",
        "This is the only stemmer which gives words which has meaning.\n",
        "See examples above."
      ],
      "metadata": {
        "id": "Q-ajrpR_yk_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"\n",
        "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
        "    -webkit-background-clip: text;\n",
        "    -webkit-text-fill-color: transparent;\n",
        "    font-size: 20px;\n",
        "    font-weight: bold;\n",
        "    text-align: center;\">\n",
        "  Exercise\n",
        "</div>\n",
        ""
      ],
      "metadata": {
        "id": "c6ZMSHSv3mIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "text = '''\n",
        "India, officially the Republic of India,[j][20] is a country in South Asia. It is the seventh-largest country in the world by area and the most populous country. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[k] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand, Myanmar, and Indonesia.\n",
        "\n",
        "Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago.[22][23][24] Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, second only to Africa in human genetic diversity.[25] Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE.[26] By at least 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest.[27][28] Its evidence today is found in the hymns of the Rigveda. Preserved by an oral tradition that was resolutely vigilant, the Rigveda records the dawning of Hinduism in India.[29] The Dravidian languages of India were supplanted in the northern and western regions.[30] By 400 BCE, stratification and exclusion by caste had emerged within Hinduism,[31] and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity.[32] Early political consolidations gave rise to the loose-knit Maurya and Gupta Empires based in the Ganges Basin.[33] Their collective era was suffused with wide-ranging creativity,[34] but also marked by the declining status of women,[35] and the incorporation of untouchability into an organised system of belief.[l][36] The Middle kingdoms exported Sanskrit language, south Indian scripts and religions of Hinduism and Buddhism to the Southeast Asia.\n",
        "'''\n",
        "\n",
        "tags = pos_tag(word_tokenize(text))\n",
        "verbs = set()\n",
        "\n",
        "for word, tag in tags:\n",
        "    if tag.startswith('V') and word.isalpha():\n",
        "        verbs.add(wnl.lemmatize(word.lower(), pos='v'))\n",
        "\n",
        "print(verbs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM58M0_wyw1U",
        "outputId": "cb17e3e4-3e85-4f01-aa8b-6798782b75bb"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'arise',\n",
              " 'arrive',\n",
              " 'base',\n",
              " 'be',\n",
              " 'bound',\n",
              " 'decline',\n",
              " 'diffuse',\n",
              " 'emerge',\n",
              " 'evolve',\n",
              " 'export',\n",
              " 'find',\n",
              " 'give',\n",
              " 'have',\n",
              " 'humans',\n",
              " 'k',\n",
              " 'land',\n",
              " 'make',\n",
              " 'mark',\n",
              " 'preserve',\n",
              " 'proclaim',\n",
              " 'settle',\n",
              " 'suffuse',\n",
              " 'supplant',\n",
              " 'unlinked',\n",
              " 'vary'}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ]
}