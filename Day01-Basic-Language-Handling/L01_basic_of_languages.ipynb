{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 20px;\n",
    "    font-weight: bold;\n",
    "    text-align: center;\">\n",
    "  Basic Python\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average age :  27.33\n",
      "Average age :  27.33\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "sent = 'They told that their ages are 25 26 and 31 respectively.'\n",
    "\n",
    "#Find the average ages in the sentence\n",
    "ar = [int(i) for i in re.findall('\\d{2,3}', sent)]\n",
    "print(f'Average age : {sum(ar)/len(ar) : .2f}')\n",
    "\n",
    "ar=[int(i) for i in sent.split(\" \") if i.isdigit()]\n",
    "print(f'Average age : {sum(ar)/len(ar) : .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§Ö‡§ú‡§Ø\n",
      "‡§Ö‡§§‡•Å‡§≤\n",
      "‡§Ö‡§ú‡§Ø ‡§µ‡§ø‡§ú‡§Ø ‡§™‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§Ö‡§§‡•Å‡§≤\n",
      "‡§Ö‡§ú‡§Ø\n",
      "6\n",
      "‡•Å "
     ]
    }
   ],
   "source": [
    "names = ['‡§Ö‡§ú‡§Ø', '‡§µ‡§ø‡§ú‡§Ø', '‡§™‡•ç‡§∞‡§ø‡§Ø‡§æ', '‡§Ö‡§§‡•Å‡§≤' ] \n",
    "for name in names:\n",
    "    if name.startswith('‡§Ö'):\n",
    "        print(name)\n",
    "\n",
    "print(' '.join(names))\n",
    "\n",
    "print('‡§µ‡§ø‡§ú‡§Ø'.replace('‡§µ‡§ø', '‡§Ö'))\n",
    "\n",
    "print(len(names[2]))\n",
    "\n",
    "for i in name[2]:\n",
    "    print(i, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('names.txt','w', encoding='utf8')\n",
    "for x in range(100):\n",
    "    f.write('‡§™‡•ç‡§∞‡§ø‡§Ø‡§æ\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 2352, 49, '‡§∞', 2351)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('r'),ord('‡§∞'), ord('1'), chr(2352), ord('‡§Ø')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§π‡§™'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '\\u0939\\u092A'\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65039"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'üòä‚ù§Ô∏èüòçüëçüòé'\n",
    "ord(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2346 2325 2379 2337 2366 "
     ]
    }
   ],
   "source": [
    "for x in '‡§™‡§ï‡•ã‡§°‡§æ':\n",
    "    print(ord(x), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 24px;\n",
    "    font-weight: bold;\n",
    "    text-align: center;\">\n",
    "  Tokenization\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting scipy==1.11.3\n",
      "  Downloading scipy-1.11.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Downloading scipy-1.11.3-cp312-cp312-win_amd64.whl (43.7 MB)\n",
      "   ---------------------------------------- 0.0/43.7 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 18.4/43.7 MB 88.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 24.6/43.7 MB 57.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 41.9/43.7 MB 66.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.5/43.7 MB 53.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 43.7/43.7 MB 42.1 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.1\n",
      "    Uninstalling scipy-1.14.1:\n",
      "      Successfully uninstalled scipy-1.14.1\n",
      "Successfully installed numpy-1.26.4 scipy-1.11.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy scipy -y\n",
    "!pip install numpy==1.26.4 scipy==1.11.3\n",
    "# !pip install --force-reinstall numpy==1.26.4 scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package indian to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DAI.STUDENTSDC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')                                # tokenizer\n",
    "nltk.download('stopwords')                            # collection of stopwords\n",
    "nltk.download('wordnet')                              # wordnet -> database of english words\n",
    "nltk.download('omw-1.4')                              # open multilingual wordnet\n",
    "nltk.download('averaged_perceptron_tagger')           # POS Tagger\n",
    "nltk.download('indian')                               # indian language POS tagger\n",
    "nltk.download('maxent_ne_chunker')                    # maxent chunking\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg,rgb(251, 255, 10), #ff758c, #ff4d6d);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 20px;\n",
    "    font-weight: bold;\n",
    "    text-align: center;\">\n",
    "  Word Tokenization\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['They', 'told', 'that', 'their', 'ages', 'of', 'mr.', 'are', '25,', '26.2', 'and', '31', 'respectively.']\n",
      "['They', 'told', 'that', 'their', 'ages', 'of', 'mr.', 'are', '25', ',', '26.2', 'and', '31', 'respectively', '.']\n"
     ]
    }
   ],
   "source": [
    "sent = 'They told that their ages of mr. are 25, 26.2 and 31 respectively.'\n",
    "print(sent.split())\n",
    "print(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'friends!', 'How', 'are', 'you?', 'Welcome', 'to', 'the', 'world', 'of', 'python', 'programming.']\n",
      "['Hello', 'friends', '!', 'How', 'are', 'you', '?', 'Welcome', 'to', 'the', 'world', 'of', 'python', 'programming', '.']\n",
      "Percentage of punctuation 20.0%\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "sent = '''Hello friends!\n",
    "How are you? Welcome to the world of python programming.'''\n",
    "\n",
    "print(sent.split())\n",
    "print(word_tokenize(sent))\n",
    "\n",
    "ar = [1 if i in punctuation else 0 for i in word_tokenize(sent)]\n",
    "ar = sum(ar)/len(ar)\n",
    "\n",
    "print(f\"Percentage of punctuation {ar*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
